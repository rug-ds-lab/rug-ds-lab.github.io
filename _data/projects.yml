- title: "Sparse Sensor Placement for Graph-Based State Estimation"
  supervisors: ["Revien Alief", "Dilek Düştegör"]
  available: true
  date: 2026-01-05
  type: ["bachelor-project", "colloquium", "master-internship", "master-thesis"]
  description: |
    This project studies sparse sensor placement in large networked systems to support accurate state estimation using graph neural networks (GNNs). The focus is on identifying critical sensor locations using graph-theoretic properties and invariants, and evaluating their impact on learning-based estimation performance. Students will implement and compare sensor placement strategies and assess their effectiveness under limited sensing. Project depth will be adjusted to BS or MS level.

- title: "Dataset Management"
  supervisors: ["Huy Truong", "Andrés Tello"]
  available: true
  date: 2025-08-25
  type: ["bachelor-internship"]
  description: |  
    Have you ever managed a large dataset? This project provides an opportunity to handle a dataset with over 8,000 downloads each month. You will reorganize the dataset by task, document it thoroughly, and create a user-friendly interface and leaderboard. The project also involves working with HPC clusters, Hugging Face libraries, and GitHub Pages for documentation. Basic Python skills and familiarity with Linux commands are required.

- title: "DL Jobs Generator"
  supervisors: ["Kawsar Haghshenas", "Mahmoud Alasmar"]
  available: true
  date: 2024-11-01
  type: ["bachelor-internship"]
  description: |
    In this project you will implement a job generator process. As an input, a JSON configuration (JSON) file and jobs generation rate (jobs per unit time) will be provided. The configuration file contains metadata about different Deep learning jobs, such as the path to the executable file and required arguments. Your task is to design and implement a generator which works as follows: Randomly select a job from the JSON file, use the metadata of the selected job to prepare a YAML/Batch script, a script template will be provided, and submit the prepared script to another process using an RPC protocol. The rate at which a job is sampled and submitted should be equal to the given generation rate. In addition, an implementation of an RPC protocol is required, the description of the protocol will be provided. You may choose any programming language for coding, but advisably to use Python. You will be provided with a supplementary code with helper functions, RPC protocol description and script/configuration files description.

- title: "Implementation of Hardware Monitoring APIs"
  supervisors: ["Kawsar Haghshenas", "Mahmoud Alasmar"]
  available: true
  date: 2024-11-01
  type: ["bachelor-internship"]
  description: |
    In this project we are developing a resource manager framework, part of this framework is to design monitoring APIs functionalities, which gathers hardware metrics upon invocation. You will be given a code template and your task is to fill in the code for some API functionalities. Supplementary programs and helper functions will be provided to be able to test your implementation. A documentation for the required API functions including their input and output parameters will be provided. This project requires C and Python programming as well as basic operating systems knowledge.

- title: "Research packages for the formal specification and verification of process compositions"
  supervisors: ["Heerko Groefsema"]
  available: true
  date: 2024-10-21
  type: ["bachelor-internship"]
  description: |  
    For our research we implemented and use a number of Java packages that allow us to specify, unfold, and verify process compositions such as business process models and service compositions. These packages require some work, including new functionality, replacing old dependencies, adding different output formats, replacing log functionality, refactoring to use certain programming patterns, and more. In this project, we would like a number of students to improve, refactor, and add functionality. This project is available for up to 5 students, which will work on separate sub-projects such as:
      - Adding rich Event Log generation from random executions of annotated Petri net models.
      - Separating embedded data annotations and allowing execution of Petri nets using data.
      - Adding functionality for colored Petri nets.
      - Implementing improved Prime Event Structures (PES) representations of processes and unfolding (i.e., creation of PES) from Petri nets.
      - Replacing old dependencies and refactoring.

- title: "In-Network Atomic Multicast Protocol Validation and Verification."
  supervisors: ["Bochra Boughzala"]
  available: true
  date: 2024-10-29
  type: ["bachelor-internship"]
  description: |
    This project involves creating a high-performance networking application using the Intel Data Plane Development Kit (DPDK). The application will receive network packets over a high-speed interface, inspect the packet header fields, and validate the protocol properties for correctness and consistency guarantees. The tool will verify protocol correctness by making sure that all receiving nodes receive the same set of packets in the exact order, guaranteeing total order and consistent state across all nodes.<br />Prerequisites: C/C++ programming language - Networking libraries and tools for protocol analysis - Logging library for error reporting.

- title: "In-Network Data Stream Processing Serialization."
  supervisors: ["Bochra Boughzala"]
  available: true
  date: 2024-10-29
  type: ["bachelor-internship"]
  description: |
    This project involves creating a high-performance networking application using the Intel Data Plane Development Kit (DPDK). The application will read entries from a specified database, convert these entries into JSON format, and send the JSON entries as packets over a high-speed network. The focus is on achieving low-latency and high-throughput performance.<br />Prerequisites: C/C++ programming language - Database Management (e.g., PostgreSQL databases).

- title: "Benchmarking AI Workloads on GPU Cluster"
  supervisors: ["Kawsar Haghshenas", "Mahmoud Alasmar"]
  available: true
  date: 2025-01-21
  type: ["bachelor-project"]
  description: |
    Understanding the characteristics of AI workloads is essential for effective resource allocation and fault tolerance mechanisms. This project focuses on benchmarking various deep neural network (DNN) models on GPUs using different profiling and monitoring tools. You will observe and analyze their runtime behavior, identify the factors affecting model performance, and propose metrics that effectively quantify their runtime characteristics. The outcome of this project is to deliver a comprehensive study on profiling DNN models with minimal overhead and maximum accuracy.<br />
    References:<br />
    <a href="https://arxiv.org/abs/1808.08512">Gao, Wanling, et al. "Data motifs: A lens towards fully understanding big data and ai workloads." Proceedings of the 27th International Conference on Parallel Architectures and Compilation Techniques. 2018., https://arxiv.org/abs/1808.08512</a>
    <a href="https://www.usenix.org/conference/osdi18/presentation/xiao">Xiao, Wencong, et al. "Gandiva: Introspective cluster scheduling for deep learning." 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18). 2018., https://www.usenix.org/conference/osdi18/presentation/xiao</a>
    <a href="https://arxiv.org/abs/2009.05257">Yang, Charlene, et al. "Hierarchical roofline performance analysis for deep learning applications." Intelligent Computing: Proceedings of the 2021 Computing Conference, Volume 2. Springer International Publishing, 2021., https://arxiv.org/abs/2009.05257</a>

- title: "DiTEC project- Unsupervised Learning for Customer Profiles in Water Distribution Networks"
  supervisors: ["Huy Truong", "Dilek Düştegör"]
  available: true
  date: 2025-01-21
  type: ["bachelor-project"]
  description: |
    Researchers studying drinking water distribution networks often rely on large-scale synthesized datasets. However, the current simulation generating these datasets faces limitations in retrieving metadata that enhances dataset accessibility. Moreover, this missing metadata, including customer profiles at each node in the network, plays a crucial role in classifying customer types and estimating their demand, particularly during peak seasons. To address this gap, the student could apply unsupervised clustering algorithms such as K-NN, K-means, or DBSCAN to identify and retrieve these customer profiles. This project requires a candidate with a solid background in Machine Learning and interest in building robust data pipelines. They will be eventually employed to extract the missing metadata for a large-scale dataset, enabling water experts to analyze water network and benchmark customer behavior efficiently.<br />
    References:<br />
    <a href="https://doi.org/10.3390/engproc2024069050">Tello, A., Truong, H., Lazovik, A., & Degeler, V. (2024). Large-scale multipurpose benchmark datasets for assessing data-driven deep learning approaches for water distribution networks. Engineering Proceedings, 69(1), 50. https://doi.org/10.3390/engproc2024069050.</a>

- title: "Node masking in Graph Neural Networks"
  supervisors: ["Huy Truong", "Dilek Düstegör"]
  available: true
  date: 2025-01-21
  type: ["bachelor-project"]
  description: |
    Working with data in the real world often leads to missing information problems, which can negatively affect the performance of deep learning models. However, in proper ways, it can boost the expressiveness of Graph Neural Network (GNN) models in node representation learning through a technique known as Node Masking. In particular, it hides arbitrary nodal features in a graph and instructs the GNN to recover the missing parts. The student can explore diverse masking strategies, such as zero masking, random node replacement, mean-neighbor substitution, shared learnable embedding, and nodal permutation. These options above should be compared and evaluated in a graph reconstruction task that applies to a water distribution network. This study will focus on finding a generative technique that effectively enhances the performance of GNN models in semi-supervised transductive learning. Students interested in joining this project should possess a machine-learning background and a deep-learning framework.<br />
    References:<br />
    <a href="https://arxiv.org/pdf/2205.10803.pdf">Hou, Zhenyu, Xiao Liu, Yuxiao Dong, Chunjie Wang, and Jie Tang. "GraphMAE: Self-Supervised Masked Graph Autoencoders." arXiv preprint arXiv:2205.10803(2022).</a>
    <a href="https://arxiv.org/pdf/2010.01179.pdf">Abboud, Ralph, Ismail Ilkan Ceylan, Martin Grohe, and Thomas Lukasiewicz. "The surprising power of graph neural networks with random node initialization." arXiv preprint arXiv:2010.01179 (2020).</a>
    <a href="https://arxiv.org/pdf/2104.13619.pdf">Hajgató, Gergely, Bálint Gyires-Tóth, and György Paál. "Reconstructing nodal pressures in water distribution systems with graph neural networks." arXiv preprint arXiv:2104.13619 (2021).</a>
    <a href="https://arxiv.org/pdf/2111.06377.pdf">He, Kaiming, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, and Ross Girshick. "Masked autoencoders are scalable vision learners." In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 16000-16009. 2022.</a>

- title: Conditional planning an overview of approaches
  supervisors: ["Heerko Groefsema"]
  available: true
  date: 2025-02-05
  type: ["student-colloquium"]
  description: |
    References:<br />
    <a href="https://www.sciencedirect.com/science/article/pii/B9780080499444500276">Peot, M. A., & Smith, D. E. (1992, January). Conditional nonlinear planning. In Artificial Intelligence Planning Systems (pp. 189-197). Morgan Kaufmann.</a>
    <a href="https://link.springer.com/chapter/10.1007/3-540-48317-9_4">Blythe, J. (1999). An overview of planning under uncertainty. Artificial intelligence today, 85-110.</a>
    <a href="https://www.jair.org/index.php/jair/article/view/10230">Rintanen, J. (1999). Constructing conditional plans by a theorem-prover. Journal of Artificial Intelligence Research, 10, 323-352.</a>
    <a href="https://dl.acm.org/doi/abs/10.5555/1642090.1642149">Karlsson, L. (2001, January). Conditional progressive planning under uncertainty. In IJCAI (pp. 431-438).</a>

- title: Verifying the data perspective of business processes
  supervisors: ["Heerko Groefsema"]
  available: true
  date: 2025-02-05
  type: ["student-colloquium"]
  description: |
    References:<br />
    <a href="https://doi.org/10.1007/978-3-031-16171-1_2">Groefsema, H., Beest, N.R.T.P.v., Governatori, G. (2022). On the Use of the Conformance and Compliance Keywords During Verification of Business Processes. In: Business Process Management Forum. BPM 2022. Lecture Notes in Business Information Processing, vol 458. Springer.</a>
    <a href="https://doi.org/10.1016/j.compind.2019.103181">H. Groefsema, N.R.T.P. van Beest, A. Armas-Cervantes, Efficient conditional compliance checking of business process models, Computers in Industry, Volume 115, 2020.</a>
    <a href="https://doi.org/10.1145/1514894.1514924">Alin Deutsch, Richard Hull, Fabio Patrizi, and Victor Vianu. 2009. Automatic verification of data-centric business processes. In Proceedings of the 12th International Conference on Database Theory (ICDT '09).</a>
    <a href="https://doi.org/10.1109/TSE.2023.3319086">N. van Beest, H. Groefsema, A. Cryer, G. Governatori, S. C. Tosatto and H. Burke, Cross-Instance Regulatory Compliance Checking of Business Process Event Logs, in IEEE Transactions on Software Engineering, vol. 49, no. 11, pp. 4917-4931, Nov. 2023.</a>

- title: Explaining Graph Neural Networks
  supervisors: ["Andrés Tello"]
  available: true
  date: 2025-02-01
  type: ["student-colloquium"]
  description: |
    References:<br />
    <a href="https://openreview.net/pdf?id=WIzzXCVYiH">Wang, X., & Shen, H. W. GNNBoundary: Towards Explaining Graph Neural Networks through the Lens of Decision Boundaries. In The Twelfth International Conference on Learning Representations.</a>
    <a href="https://openreview.net/pdf?id=IjMUGuUmBI">Müller, P., Faber, L., Martinkus, K., & Wattenhofer, R. (2024). GraphChef: Decision-Tree Recipes to Explain Graph Neural Networks. In The Twelfth International Conference on Learning Representations.</a>
    <a href="https://openreview.net/pdf?id=2Q8TZWAHv4">Lu, S., Mills, K. G., He, J., Liu, B., & Niu, D. (2024). GOAt: Explaining graph neural networks via graph output attribution. arXiv preprint arXiv:2401.14578.</a>
    <a href="https://arxiv.org/pdf/2209.07924">Wang, X., & Shen, H. W. (2022). Gnninterpreter: A probabilistic generative model-level explanation for graph neural networks. arXiv preprint arXiv:2209.07924.</a>

- title: Generalization in Graph Neural Networks
  supervisors: ["Andrés Tello"]
  available: true
  date: 2025-02-01
  type: ["student-colloquium"]
  description: |
    References:<br />
    <a href="https://openreview.net/pdf?id=qaJxPhkYtD">Kanatsoulis, C., & Ribeiro, A. Counting Graph Substructures with Graph Neural Networks. In The Twelfth International Conference on Learning Representations.</a>
    <a href="https://openreview.net/pdf?id=4IT2pgc9v6">Liu, H., Feng, J., Kong, L., Liang, N., Tao, D., Chen, Y., & Zhang, M. (2023). One for all: Towards training one graph model for all classification tasks. arXiv preprint arXiv:2310.00149.</a>
    <a href="https://openreview.net/pdf?id=EYjfLeJL4l">Lee, H., Yoon, K., 2023. Towards better generalization with flexible representation of multi-module graph neural networks. Transactions on Machine Learning Research.</a>
    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_Mind_the_Label_Shift_of_Augmentation-Based_Graph_OOD_Generalization_CVPR_2023_paper.pdf">Yu, J., Liang, J., & He, R. (2023). Mind the Label Shift of Augmentation-based Graph OOD Generalization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 11620-11630).</a>

- title: Multimodality Graph Foundation Models
  supervisors: ["Huy Truong"]
  available: true
  date: 2025-01-21
  type: ["student-colloquium"]
  description: |
    References:<br />
    <a href="https://www.researchgate.net/publication/371786545_Otter-Knowledge_benchmarks_of_multimodal_knowledge_graph_representation_learning_from_different_sources_for_drug_discovery">Lam, Hoang Thanh, et al. "Otter-Knowledge: benchmarks of multimodal knowledge graph representation learning from different sources for drug discovery." *arXiv preprint arXiv:2306.12802* (2023).</a>
    <a href="https://aclanthology.org/2024.findings-emnlp.132/">Xia, Lianghao, Ben Kao, and Chao Huang. "Opengraph: Towards open graph foundation models." *arXiv preprint arXiv:2403.01121* (2024).</a>
    <a href="https://www.nature.com/articles/s42256-023-00624-6">Ektefaie, Yasha, et al. "Multimodal learning with graphs." *Nature Machine Intelligence* 5.4 (2023): 340-350.</a>

- title: Test-Time Training
  supervisors: ["Huy Truong"]
  available: true
  date: 2025-01-21
  type: ["student-colloquium"]
  description: |
    References:<br />
    <a href="http://proceedings.mlr.press/v119/sun20b/sun20b.pdf">Sun, Yu, et al. "Test-time training with self-supervision for generalization under distribution shifts." International conference on machine learning. PMLR, 2020.</a>
    <a href="https://proceedings.neurips.cc/paper/2021/hash/b618c3210e934362ac261db280128c22-Abstract.html">Liu, Yuejiang, et al. "Ttt++: When does self-supervised test-time training fail or thrive?." Advances in Neural Information Processing Systems 34 (2021): 21808-21820.</a>
    <a href="https://link.springer.com/article/10.1007/s11263-024-02181-w">Liang, Jian, Ran He, and Tieniu Tan. "A comprehensive survey on test-time adaptation under distribution shifts." *International Journal of Computer Vision* (2024): 1-34.</a>
    <a href="https://arxiv.org/abs/2501.00663">Behrouz, Ali, Peilin Zhong, and Vahab Mirrokni. "Titans: Learning to Memorize at Test Time." arXiv preprint arXiv:2501.00663 (2024).</a>

- title: Cluster Scheduling for DLT workloads
  supervisors: ["Kawsar Haghshenas", "Mahmoud Alasmar"]
  available: true
  date: 2025-01-27
  type: ["student-colloquium"]
  description: |
    References:<br />
    <a href="https://www.usenix.org/conference/osdi18/presentation/xiao">Wencong Xiao, Romil Bhardwaj, Ramachandran Ramjee, Muthian Sivathanu, Nipun Kwatra, Zhenhua Han, Pratyush Patel et al. "Gandiva: Introspective Cluster Scheduling for Deep Learning." In 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18), pp. 595-610. 2018.</a>
    <a href="https://www.usenix.org/conference/atc23/presentation/weng">Weng, Q., Yang, L., Yu, Y., Wang, W., Tang, X., Yang, G., & Zhang, L. (2023). Beware of Fragmentation: Scheduling {GPU-Sharing} Workloads with Fragmentation Gradient Descent. In 2023 USENIX Annual Technical Conference (USENIX ATC 23) (pp. 995-1008).</a>
    <a href="https://arxiv.org/abs/2408.08586">Zhang, X., Zhao, H., Xiao, W., Jia, X., Xu, F., Li, Y., ... & Liu, F. (2024). Rubick: Exploiting Job Reconfigurability for Deep Learning Cluster Scheduling. arXiv preprint arXiv:2408.08586.</a>
    <a href="https://www.usenix.org/conference/nsdi23/presentation/lai-fan">Lai, F., Dai, Y., Madhyastha, H. V., & Chowdhury, M. (2023). {ModelKeeper}: Accelerating {DNN} training via automated training warmup. In 20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23) (pp. 769-785).</a>

- title: Estimating Deep Learning GPU Memory Consumption
  supervisors: ["Kawsar Haghshenas", "Mahmoud Alasmar"]
  available: true
  date: 2023-12-11
  type: ["student-colloquium"]
  description: |
    References:<br />
    <a href="https://dl.acm.org/doi/abs/10.1145/3368089.3417050">Yanjie Gao, Yu Liu, Hongyu Zhang, Zhengxian Li, Yonghao Zhu, Haoxiang Lin, and Mao Yang. "Estimating GPU memory consumption of deep learning models." In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 1342-1352. 2020.</a>
    <a href="https://ieeexplore.ieee.org/abstract/document/9755116">Haiyi Liu, Shaoying Liu, Chenglong Wen, and W. Eric Wong. "TBEM: Testing-Based GPU-Memory Consumption Estimation for Deep Learning." IEEE Access, 10, pp.39674-39680. 2022.</a>
    <a href="https://arxiv.org/abs/2205.12095">Lu Bai, Weixing Ji, Qinyuan Li, Xilai Yao, Wei Xin, and Wanyi Zhu. "Dnnabacus: Toward accurate computational cost prediction for deep neural netw." arXiv preprint arXiv:2205.12095. 2022.</a>
    <a href="https://ieeexplore.ieee.org/abstract/document/10172674">Yanjie Gao, Xianyu Gu, Hongyu Zhang, Haoxiang Lin, and Mao Yang. "Runtime performance prediction for deep learning models with graph neural network." In IEEE/ACM 45th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP), pp. 368-380. 2023.</a>

- title: DiTEC project- Building a collection of Graph Self-Supervised Learning tasks
  supervisors: ["Huy Truong"]
  available: true
  date: 2025-04-03
  type: ["master-internship"]
  description: |
    Self-supervised learning (SSL) has shown great potential in enhancing the capabilities of large foundation models, but its application to graph modalities remains underexplored. This project aims to investigate popular SSL tasks across node-level, link-level, and graph-level challenges, as well as more complex graph representation learning approaches. As a researcher of the project, the candidate will develop a framework that enables users to train deep learning models using these tasks on independent datasets. The final deliverables will include the implementation code and a report detailing the problem and the proposed solution. The ideal candidate should have a background in machine learning, and experience with at least one deep learning framework.
    <br />References:<br />
    <a href="https://ieeexplore.ieee.org/document/9770382/">Liu, Yixin, et al. "Graph self-supervised learning: A survey." *IEEE transactions on knowledge and data engineering* 35.6 (2022): 5879-5900.</a>
    <a href="https://ieeexplore.ieee.org/document/9632431/">Wu, Lirong, et al. "Self-supervised learning on graphs: Contrastive, generative, or predictive." *IEEE Transactions on Knowledge and Data Engineering* 35.4 (2021): 4216-4235.</a>

- title: DiTEC project- Inverse problem in Water Distribution Networks
  supervisors: ["Huy Truong"]
  available: true
  date: 2025-04-03
  type: ["master-internship"]
  description: |
    Water researchers have relied on simulations to monitor the behavior of Water Distribution Networks. These simulations require a comprehensive set of parameters- such as elevation, demand, and pipe diameters-to determine hydraulic states accurately. This increases labor cost, time consumption and, therefore, poses a significant challenge. But what if we could reverse the process and let AI infer the missing pieces? Building on this idea, the project explores an innovative approach: leveraging data-driven deep learning methods to predict initial input conditions based on available output states. As a researcher on this project, the candidate will select and train a cutting-edge Graph Neural Network on a massive dataset. As a result, the model should be able to predict initial conditions while considering the structural and physical constraints. The candidate will submit the implementation code and a report detailing the problem and the proposed solution. The ideal candidate should have a background in machine learning and be familiar with at least one deep-learning framework.
    <br />References:<br />
    <a href="https://arxiv.org/abs/2503.17167">Truong, Huy, et al. "DiTEC-WDN: A Large-Scale Dataset of Hydraulic Scenarios across Multiple Water Distribution Networks." (2025).</a>

- title: DiTEC project- Bio-inspired Water Network Design
  supervisors: ["Huy Truong"]
  available: true
  date: 2025-04-03
  type: ["master-internship"]
  description: |
    Designing Water Distribution Networks (WDN) has been portrayed as a complex, labor, and time-consuming process. To alleviate this, the project aims to automate the design using Evolution Strategy (ES). In particular, these algorithms should search and optimize values of hydraulic parameters, such as nodal elevation, pump speed, and pipe length, to construct a complete simulation configuration. This configuration should follow the local, structural, and physical restrictions (i.e., multi-objective optimization). As a researcher on this project, the candidate will explore an ES framework to develop the optimization algorithm and apply it to a water distribution domain. As such, the candidate should be familiar with machine-learning experiments. As deliverables, the candidate should submit the report and implementation code that generates optimized configurations. These configurations will help water researchers simulate, analyze, and understand the WDN’s behavior and enhance the monitoring capability of these systems in practice.
    <br />References:<br />
    <a href="https://link.springer.com/article/10.1007/s11042-023-17167-y">Gad, Ahmed Fawzy. "Pygad: An intuitive genetic algorithm python library." *Multimedia tools and applications* 83.20 (2024): 58029-58042.</a>
    <a href="https://arxiv.org/abs/2302.12600">Toklu, Nihat Engin, et al. "Evotorch: Scalable evolutionary computation in python." *arXiv preprint arXiv:2302.12600* (2023).</a>
    <a href="https://dl.acm.org/doi/abs/10.1145/3583133.3590733">Lange, Robert Tjarko. "evosax: Jax-based evolution strategies, 2022." *URL http://github.com/RobertTLange/evosax* 7 (2022).</a>

- title: Can we train a Neural Network with Forward-Forward “harmoniously”?
  supervisors: ["Huy Truong"]
  available: true
  date: 2025-04-03
  type: ["master-internship"]
  description: |
    Back Propagation(BP) is a de facto approach to training neural network models. Nevertheless, it is biologically implausible and requires complete knowledge (i.e., tracks the entire flow of information from start to end of a model) to perform a backward pass. Instead, an alternative approach called Forward-Forward(FF) can replace the backward pass with an additional forward one and update the model weights in an unsupervised fashion. In particular, FF performs forward passes using positive and negative inputs, respectively, and, therefore, employs the difference between the two activation versions at each layer in the neural network to compute the loss and update weights. Here, the project studies the behavior of FF employing different losses: (1) cross-entropy and (2) harmonic loss. Also, it is valuable to study the relevance between harmonic loss and FF in terms of distance metrics or geometric properties in an embedding space. As a deliverable, the candidate should submit a detailed report and implementation code. For primary requirements, the candidate should be familiar with one of the deep learning frameworks and have experience in setting up machine learning experiments.
    <br />References:<br />
    <a href="https://arxiv.org/abs/2212.13345">Hinton, Geoffrey. "The forward-forward algorithm: Some preliminary investigations." *arXiv preprint arXiv:2212.13345* (2022).</a>
    <a href="https://arxiv.org/html/2502.01628v1">Baek, David D., et al. "Harmonic Loss Trains Interpretable AI Models." *arXiv preprint arXiv:2502.01628* (2025).</a>

- title: Leveraging Structural Similarity for Performance Estimation of Deep Learning Training Jobs
  supervisors: ["Mahmoud Alasmar"]
  available: true
  date: 2025-04-04
  type: ["master-internship"]
  description: |
    Deep learning (DL) workload-aware schedulers make decisions based on performance data collected through a process called profiling. However, profiling each job individually is computationally expensive, reducing the practicality of such approaches. Fortunately, DL models exhibit structural similarities that can be leveraged to develop alternative methods for performance estimation. One promising approach involves representing DL models as graphs and measuring their similarity using Graph Edit Distance (GED) [1]. By analyzing the structural similarities between models, we can potentially predict the performance of one model based on the known performance of another, reducing the need for extensive profiling. In this project, you will: Study and implement the similarity matching mechanism proposed in [2], compare runtime performance of similar DL models, focusing on key metrics such as GPU utilization and power consumption, and investigate the relationship between model similarity and performance predictability, trying to answer the following question: Given two similar DL models and the performance of one, what can we infer about the performance of the other? You will work with a selected set of DL training models, and performance metrics will be collected using Nvidia's GPU profiling tools, such as DCGM.
    <br />References:<br />
    <a href="https://doi.org/10.1145/2882903.2915236">Fei Bi, Lijun Chang, Xuemin Lin, Lu Qin, and Wenjie Zhang. 2016. Efficient Subgraph Matching by Postponing Cartesian Products. In Proceedings of the 2016 International Conference on Management of Data (SIGMOD '16). Association for Computing Machinery, New York, NY, USA, 1199–1214</a>
    <a href="https://www.usenix.org/conference/nsdi23/presentation/lai-fan">Lai, F., Dai, Y., Madhyastha, H. V., & Chowdhury, M. (2023). {ModelKeeper}: Accelerating {DNN} training via automated training warmup. In 20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23) (pp. 769-785).</a>

- title: Model Checking for Environmental Sustainability
  supervisors: ["Heerko Groefsema", "Michel Medema"]
  available: true
  date: 2025-12-05
  type: ["bachelor-project", "master-project"]
  description: |
    Organisations are increasingly concerned with environmental sustainability for various reasons (e.g., legislative, economic, ecological, or social). Quantifying sustainability performance across different dimensions is necessary for fulfilling legislative requirements and evaluating improvement efforts. In this project you will extend existing model checking approaches so that they can deal with business process models in which key environmental indicators have been attached to tasks and subprocesses along with possible target values for those indicators that should be enforced during process execution.

- title: Runtime Compliance Checking for Camunda 8
  supervisors: ["Heerko Groefsema", "Michel Medema"]
  available: true
  date: 2025-12-05
  type: ["bachelor-project", "master-internship", "master-project"]
  description: |
    Organisations are increasingly concerned with environmental sustainability for various reasons (e.g., legislative, economic, ecological, or social). Quantifying sustainability performance across different dimensions is necessary for fulfilling legislative requirements and evaluating improvement efforts. In this project you will integrate an existing compliance checking tool into the Camunda 8 platform.

- title: Verification of Security and Privacy concepts in BPMN Choreography diagrams
  supervisors: ["Heerko Groefsema"]
  available: true
  date: 2025-12-05
  type: ["bachelor-project", "master-project"]
  description: |
    Where process models define the flow of activities of participants, choreographies describe interactions between participants. Within such interactions, the security and privacy related concepts of separation of duties and division of knowledge are important. The former specifies that no one person has the privileges to misuse the system, either by error or fraudulent behavior, while the latter defines the absence of total knowledge within a single person, such that the knowledge can not be abused. The problem is, how do we specify such concepts and what kind of model is required to verify these concepts? In this project we ask the student to devise an approach to formally specify and verify these concepts given a BPMN Choreography Diagram.
    <br />References:<br />
    <a href="https://www.omg.org/spec/BPMN/2.0/PDF" rel="nofollow">OMG. Business process model and notation (BPMN) version 2.0, 2011.</a>
    <a href="https://doi.org/10.1007/978-3-319-65000-5_3" rel="nofollow">Pullonen, Pille &amp; Matulevičius, Raimundas &amp; Bogdanov, Dan. (2017). PE-BPMN: Privacy-Enhanced Business Process Model and Notation. 40-56.</a>
    <a href="https://github.com/rug-ds-lab/BPMVerification" rel="nofollow">BPMVerification package</a>

- title: Obtaining Alignments from Transition Graphs
  supervisors: ["Heerko Groefsema"]
  available: true
  date: 2025-12-05
  type: ["bachelor-project", "master-project"]
  description: |
    The practice of checking conformance of business process models has revolutionized the industry through the amount of insight it creates into the process flows of businesses. Conformance checking entails matching an event log (which details events of past executions) against a business process model (which details the prescribed process flow) through a so called alignment. Any deviation from the prescribed process flow is detected and reported. Generally, alignments are obtained by matching the so called token replay of process models (e.g., Petri nets) against events in logs. Our Transition Graphs are also obtained from token replays, but offer further insight into parallel executions than regular Reachability Graphs. As a result, we are interested in the applicability of obtaining alignments using Transition Graphs, especially when matched against event logs that include lifecycle events and thus offer parallel execution data. In this project we ask the student to implement and evaluate the applicability of such an approach.
    <br />References:<br />
    <a href="https://doi.org/10.1109/TSC.2016.2579621" rel="nofollow">H. Groefsema, N.R.T.P. van Beest, and M. Aiello (2016) A Formal Model for Compliance Verification of Service Compositions. IEEE Transactions on Service Computing.</a>
    <a href="https://link.springer.com/content/pdf/10.1007/978-3-319-99414-7.pdf" rel="nofollow">Carmona, Josep, et al. "Conformance checking." Switzerland: Springer.[Google Scholar] (2018).</a>
    <a href="https://github.com/rug-ds-lab/BPMVerification" rel="nofollow">BPMVerification package</a>

- title: Obtaining Alignments from behavior
  supervisors: ["Heerko Groefsema"]
  available: true
  date: 2025-12-05
  type: ["master-project"]
  description: |
    The practice of checking conformance of business process models has revolutionized the industry through the amount of insight it creates into the process flows of businesses. Conformance checking entails matching an event log (which details events of past executions) against a business process model (which details the prescribed process flow) through a so called alignment. Any deviation from the prescribed process flow is detected and reported. Generally, alignments are obtained by matching the so called token replay of process models (e.g., Petri nets) against events in logs. Instead, we would like to investigate comparing event logs against a specification of ordering relations to achieve a significant performance increase. 

